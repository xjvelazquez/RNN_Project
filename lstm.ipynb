{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on NLP From Scratch: Generating Names with a Character-Level RNN\n",
    "*************************************************************\n",
    "by: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import random\n",
    "from random import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1,nonlinearity='tanh', bias=True, batch_first=False,\n",
    "                dropout=0, bidirectional=False):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        self.lstm = nn.RNN(input_size=input_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers,nonlinearity=nonlinearity, bias=bias, batch_first=batch_first,\n",
    "                           dropout=dropout, bidirectional=bidirectional)\n",
    "#         self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "#         self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "\n",
    "        self.o2o = nn.Linear(self.num_directions * hidden_size, output_size)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, my_input, hidden):\n",
    "#         input_combined = torch.cat((category, input, hidden), 1)\n",
    "#         hidden = self.i2h(input_combined)\n",
    "#         output = self.i2o(input_combined)\n",
    "#         output_combined = torch.cat((hidden, output), 1)\n",
    "#         output = self.o2o(output_combined)\n",
    "#         output = self.dropout(output)\n",
    "        output, hidden = self.lstm(my_input, hidden)\n",
    "        output = self.o2o(output)\n",
    "#         output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch=1, device=torch.device('cpu')):\n",
    "        return torch.zeros(self.num_layers * self.num_directions,1,self.hidden_size, device=device)\n",
    "#         return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, bias=True, batch_first=False,\n",
    "                dropout=0, bidirectional=False):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, bias=bias, batch_first=batch_first,\n",
    "                           dropout=dropout, bidirectional=bidirectional)\n",
    "#         self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "#         self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "\n",
    "        self.o2o = nn.Linear(self.num_directions * hidden_size, output_size)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, my_input, hidden):\n",
    "#         input_combined = torch.cat((category, input, hidden), 1)\n",
    "#         hidden = self.i2h(input_combined)\n",
    "#         output = self.i2o(input_combined)\n",
    "#         output_combined = torch.cat((hidden, output), 1)\n",
    "#         output = self.o2o(output_combined)\n",
    "#         output = self.dropout(output)\n",
    "        output, hidden = self.lstm(my_input, hidden)\n",
    "        output = self.o2o(output)\n",
    "#         output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch=1, device=torch.device('cpu')):\n",
    "        return (torch.zeros(self.num_layers * self.num_directions,1,self.hidden_size, device=device), torch.zeros(self.num_layers * self.num_directions,batch,self.hidden_size,device=device))\n",
    "#         return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def string_to_chars(original):\n",
    "    raw_lines = original.splitlines()\n",
    "\n",
    "    def proc_line(l): return [l] if l == '<start>' or l == '<end>' else list(l)\n",
    "    chars = reduce(lambda x, y : x + ['\\n'] + y, list(map(proc_line, raw_lines)))\n",
    "    assert original == ''.join(chars)\n",
    "    return chars\n",
    "\n",
    "def make_encoder(raw):\n",
    "    chars = string_to_chars(raw)\n",
    "    decoder = [c for c in Counter(chars)]\n",
    "    decoder = sorted(decoder)\n",
    "    return {c:i for i, c in enumerate(decoder)}, decoder\n",
    "\n",
    "def split_songs(raw):\n",
    "    return re.findall('(<start>.*?<end>)',raw,flags=re.DOTALL)\n",
    "\n",
    "# train_songs = list(map(string_to_chars, split_songs(raw_train)))\n",
    "\n",
    "# reconstructed = '\\n'.join(map(''.join, train_songs))\n",
    "# encoder, decoder = make_encoder(raw_train)\n",
    "# n_chars = len(decoder)\n",
    "\n",
    "def song_to_tensor_chunks(song,encoder, decoder):\n",
    "    training_chunks = []\n",
    "    target_chunks = []\n",
    "    for i in range(0,len(song),100):\n",
    "        start = i\n",
    "        if start+100 > len(song) - 1:\n",
    "            end = len(song)\n",
    "            target_range = list(np.arange(start + 1, end,dtype=np.int)) + [int(end - 1)]\n",
    "        else:\n",
    "            end = start + 100\n",
    "            target_range = np.arange(start+1, end+1, dtype=np.int)\n",
    "        chunk = torch.zeros(end-start, 1, n_chars)\n",
    "        for i, c in enumerate(song[start:end]):\n",
    "            chunk[i,0,encoder[c]] = 1\n",
    "        target_chunk = []\n",
    "        for i in target_range:\n",
    "            target_chunk.append(encoder[song[i]])\n",
    "        target_chunks.append(torch.tensor(target_chunk))\n",
    "        training_chunks.append(chunk)\n",
    "    return training_chunks, target_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = open('train.txt').read()\n",
    "train_songs = list(map(string_to_chars, split_songs(raw_train)))\n",
    "\n",
    "reconstructed = '\\n'.join(map(''.join, train_songs))\n",
    "encoder, decoder = make_encoder(raw_train)\n",
    "n_chars = len(decoder)\n",
    "val_songs = list(map(string_to_chars, split_songs(open('val.txt').read())))\n",
    "test_songs = list(map(string_to_chars, split_songs(open('test.txt').read())))\n",
    "assert reconstructed == raw_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience during training we'll make a ``randomTrainingExample``\n",
    "function that fetches a random (category, line) pair and turns them into\n",
    "the required (category, input, target) tensors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network\n",
    "--------------------\n",
    "\n",
    "In contrast to classification, where only the last output is used, we\n",
    "are making a prediction at every step, so we are calculating loss at\n",
    "every step.\n",
    "\n",
    "The magic of autograd allows you to simply sum these losses at each step\n",
    "and call backward at the end.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(song,optimizer=None, device=torch.device('cpu')):\n",
    "    train_chunks, target_chunks = song_to_tensor_chunks(song, encoder,decoder)\n",
    "    hidden = rnn.initHidden(device=device)\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for input_line_tensor, target_line_tensor in zip(train_chunks,target_chunks):\n",
    "        target_line_tensor.unsqueeze_(-1)\n",
    "        for i in range(input_line_tensor.size(0)):\n",
    "            output, hidden = rnn(input_line_tensor[i].view((1,1,n_chars)).to(device), hidden)\n",
    "    #         print(output)\n",
    "            l = criterion(output.view((1,n_chars)), target_line_tensor[i].to(device))\n",
    "            loss += l / input_line_tensor.size(0)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item() / len(train_chunks)\n",
    "def test(rnn, song, device=torch.device('cpu')):\n",
    "    train_chunks, target_chunks = song_to_tensor_chunks(song, encoder,decoder)\n",
    "    hidden = rnn.initHidden(device=device)\n",
    "    loss = 0\n",
    "    for input_line_tensor, target_line_tensor in zip(train_chunks,target_chunks):\n",
    "        target_line_tensor.unsqueeze_(-1)\n",
    "        output, hidden = rnn(input_line_tensor.to(device), hidden)\n",
    "        seq_len,_ =target_line_tensor.size()\n",
    "        l = criterion(output.view((seq_len,n_chars)), target_line_tensor.view((seq_len)).to(device))\n",
    "        loss += l\n",
    "    return output, loss.item() / len(train_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn = RNN(n_chars, 256, n_chars).to(device)\n",
    "# name='rnn_256'\n",
    "# version_to_load = 16\n",
    "# rnn.load_state_dict(torch.load(f'{name}_{version_to_load}.pt'))\n",
    "# rnn = rnn.to(device)\n",
    "# train_loss = list(map(float,(open(f'{name}_train_loss_{version_to_load}.csv').read().splitlines())))\n",
    "# val_loss = list(map(float,(open(f'{name}_val_loss_{version_to_load}.csv').read().splitlines())))\n",
    "# print(len(train_loss))\n",
    "# start_epoch = len(train_loss)\n",
    "# optimizer = torch.optim.Adam(rnn.parameters())\n",
    "\n",
    "name='Real_rnn_256'\n",
    "rnn = RNN(n_chars, 256, n_chars).to(device)\n",
    "rnn = rnn.to(device)\n",
    "optimizer = torch.optim.Adam(rnn.parameters())\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (0 0%) 4.5545\n",
      "0m 47s (80 9%) 4.3025\n",
      "1m 39s (160 19%) 3.7543\n",
      "2m 24s (240 29%) 2.9947\n",
      "3m 8s (320 39%) 3.0242\n",
      "3m 57s (400 49%) 2.7058\n",
      "4m 38s (480 59%) 2.5840\n",
      "5m 27s (560 69%) 2.5796\n",
      "6m 10s (640 79%) 2.3601\n",
      "6m 55s (720 89%) 2.2395\n",
      "7m 47s (800 99%) 2.1557\n",
      "Epoch 0 7m 50s val loss: 2.4502 train loss: 2.9528\n",
      "\n",
      "7m 50s (0 0%) 2.2302\n",
      "8m 36s (80 9%) 2.2996\n",
      "9m 25s (160 19%) 2.2142\n",
      "10m 13s (240 29%) 2.0775\n",
      "10m 59s (320 39%) 1.8738\n",
      "11m 42s (400 49%) 2.6558\n",
      "12m 35s (480 59%) 2.5364\n",
      "13m 21s (560 69%) 1.5393\n",
      "14m 4s (640 79%) 2.1492\n",
      "14m 52s (720 89%) 2.0018\n",
      "15m 38s (800 99%) 1.7250\n",
      "Epoch 1 15m 43s val loss: 2.3261 train loss: 2.2152\n",
      "\n",
      "15m 43s (0 0%) 1.9435\n",
      "16m 32s (80 9%) 2.6787\n",
      "17m 16s (160 19%) 1.7009\n",
      "18m 4s (240 29%) 3.8890\n",
      "18m 49s (320 39%) 3.2556\n",
      "19m 36s (400 49%) 1.6559\n",
      "20m 22s (480 59%) 2.0400\n",
      "21m 11s (560 69%) 2.6149\n",
      "21m 54s (640 79%) 1.7506\n",
      "22m 41s (720 89%) 1.8676\n",
      "23m 32s (800 99%) 2.1413\n",
      "Epoch 2 23m 35s val loss: 1.9820 train loss: 2.0114\n",
      "\n",
      "23m 36s (0 0%) 2.2123\n",
      "24m 21s (80 9%) 1.7671\n",
      "25m 7s (160 19%) 1.6912\n",
      "25m 52s (240 29%) 1.4729\n",
      "26m 42s (320 39%) 1.6381\n",
      "27m 26s (400 49%) 1.3610\n",
      "28m 15s (480 59%) 1.6850\n",
      "29m 1s (560 69%) 1.8414\n",
      "29m 46s (640 79%) 1.8078\n",
      "30m 34s (720 89%) 2.0248\n",
      "31m 21s (800 99%) 1.8123\n",
      "Epoch 3 31m 25s val loss: 1.9255 train loss: 1.8608\n",
      "\n",
      "31m 25s (0 0%) 1.4566\n",
      "32m 12s (80 9%) 2.0231\n",
      "33m 0s (160 19%) 1.3135\n",
      "33m 52s (240 29%) 2.0050\n",
      "34m 39s (320 39%) 1.1504\n",
      "35m 22s (400 49%) 1.4534\n",
      "36m 9s (480 59%) 1.6807\n",
      "36m 55s (560 69%) 2.5567\n",
      "37m 41s (640 79%) 1.6137\n",
      "38m 22s (720 89%) 1.6654\n",
      "39m 11s (800 99%) 1.6286\n",
      "Epoch 4 39m 16s val loss: 1.9926 train loss: 1.7803\n",
      "\n",
      "39m 16s (0 0%) 1.7345\n",
      "40m 4s (80 9%) 2.1219\n",
      "40m 43s (160 19%) 1.2209\n",
      "41m 31s (240 29%) 1.6432\n",
      "42m 19s (320 39%) 1.1052\n",
      "43m 3s (400 49%) 1.6522\n",
      "43m 46s (480 59%) 1.6710\n",
      "44m 23s (560 69%) 1.7386\n",
      "45m 2s (640 79%) 1.3849\n",
      "45m 49s (720 89%) 1.9664\n",
      "46m 33s (800 99%) 1.8485\n",
      "Epoch 5 46m 37s val loss: 1.8771 train loss: 1.7646\n",
      "\n",
      "46m 37s (0 0%) 1.5148\n",
      "47m 28s (80 9%) 1.6219\n",
      "48m 13s (160 19%) 2.0208\n",
      "49m 3s (240 29%) 2.1711\n",
      "49m 51s (320 39%) 2.3483\n",
      "50m 37s (400 49%) 1.2649\n",
      "51m 18s (480 59%) 1.4993\n",
      "52m 0s (560 69%) 1.3768\n",
      "52m 49s (640 79%) 1.8789\n",
      "53m 36s (720 89%) 1.5865\n",
      "54m 24s (800 99%) 2.6538\n",
      "Epoch 6 54m 26s val loss: 1.8783 train loss: 1.6679\n",
      "\n",
      "54m 27s (0 0%) 1.2186\n",
      "55m 19s (80 9%) 1.9299\n",
      "56m 3s (160 19%) 1.9861\n",
      "56m 49s (240 29%) 1.0279\n",
      "57m 36s (320 39%) 1.9151\n",
      "58m 28s (400 49%) 1.4496\n",
      "59m 15s (480 59%) 1.8643\n",
      "60m 0s (560 69%) 2.9593\n",
      "60m 39s (640 79%) 1.5861\n",
      "61m 14s (720 89%) 1.4505\n",
      "61m 48s (800 99%) 1.5039\n",
      "Epoch 7 61m 51s val loss: 1.8347 train loss: 1.6329\n",
      "\n",
      "61m 51s (0 0%) 1.1798\n",
      "62m 37s (80 9%) 1.4725\n",
      "63m 29s (160 19%) 2.2678\n",
      "64m 11s (240 29%) 1.4262\n",
      "64m 56s (320 39%) 0.9400\n",
      "65m 45s (400 49%) 1.8732\n",
      "66m 35s (480 59%) 1.0065\n",
      "67m 24s (560 69%) 1.4537\n",
      "68m 8s (640 79%) 1.6639\n",
      "68m 55s (720 89%) 1.3212\n",
      "69m 37s (800 99%) 1.0688\n",
      "Epoch 8 69m 41s val loss: 1.8345 train loss: 1.5903\n",
      "\n",
      "69m 41s (0 0%) 1.6012\n",
      "70m 22s (80 9%) 2.1566\n",
      "71m 18s (160 19%) 1.1409\n",
      "72m 3s (240 29%) 1.7689\n",
      "72m 49s (320 39%) 1.8194\n",
      "73m 30s (400 49%) 1.5391\n",
      "74m 16s (480 59%) 1.3964\n",
      "75m 3s (560 69%) 1.3746\n",
      "75m 50s (640 79%) 1.8171\n",
      "76m 36s (720 89%) 1.5959\n",
      "77m 18s (800 99%) 1.3625\n",
      "Epoch 9 77m 21s val loss: 1.8516 train loss: 1.6136\n",
      "\n",
      "77m 21s (0 0%) 1.4398\n",
      "78m 8s (80 9%) 1.4211\n",
      "78m 51s (160 19%) 1.6950\n",
      "79m 42s (240 29%) 1.5791\n",
      "80m 29s (320 39%) 1.3379\n",
      "81m 19s (400 49%) 2.0536\n",
      "82m 4s (480 59%) 2.2130\n",
      "82m 47s (560 69%) 2.1997\n",
      "83m 31s (640 79%) 1.0318\n",
      "84m 19s (720 89%) 1.2888\n",
      "85m 6s (800 99%) 1.6128\n",
      "Epoch 10 85m 9s val loss: 1.8131 train loss: 1.5439\n",
      "\n",
      "85m 9s (0 0%) 1.3920\n",
      "85m 50s (80 9%) 1.5840\n",
      "86m 34s (160 19%) 1.3646\n",
      "87m 21s (240 29%) 1.3710\n",
      "88m 11s (320 39%) 1.0453\n",
      "88m 56s (400 49%) 1.3998\n",
      "89m 42s (480 59%) 1.6410\n",
      "90m 26s (560 69%) 1.3735\n",
      "91m 12s (640 79%) 1.8181\n",
      "92m 0s (720 89%) 1.6622\n",
      "92m 48s (800 99%) 1.8485\n",
      "Epoch 11 92m 52s val loss: 1.8712 train loss: 1.5111\n",
      "\n",
      "92m 52s (0 0%) 0.9640\n",
      "93m 40s (80 9%) 1.5344\n",
      "94m 23s (160 19%) 1.1613\n",
      "95m 6s (240 29%) 1.5040\n",
      "95m 57s (320 39%) 1.4204\n",
      "96m 39s (400 49%) 1.2195\n",
      "97m 18s (480 59%) 1.5715\n",
      "97m 56s (560 69%) 1.7858\n",
      "98m 29s (640 79%) 1.3614\n",
      "99m 8s (720 89%) 1.6305\n",
      "99m 42s (800 99%) 1.4468\n",
      "Epoch 12 99m 45s val loss: 1.8175 train loss: 1.4866\n",
      "\n",
      "99m 45s (0 0%) 1.4768\n",
      "100m 30s (80 9%) 1.7963\n",
      "101m 17s (160 19%) 1.6660\n",
      "102m 6s (240 29%) 1.3233\n",
      "102m 46s (320 39%) 0.9875\n",
      "103m 30s (400 49%) 1.3236\n",
      "104m 19s (480 59%) 1.5916\n",
      "105m 8s (560 69%) 1.6614\n",
      "105m 51s (640 79%) 1.7003\n",
      "106m 37s (720 89%) 1.4048\n",
      "107m 20s (800 99%) 1.3313\n",
      "Epoch 13 107m 24s val loss: 1.8216 train loss: 1.4668\n",
      "\n",
      "107m 25s (0 0%) 1.5053\n",
      "108m 8s (80 9%) 1.5667\n",
      "108m 58s (160 19%) 1.4061\n",
      "109m 42s (240 29%) 1.1463\n",
      "110m 25s (320 39%) 1.7503\n",
      "111m 13s (400 49%) 1.4845\n",
      "112m 1s (480 59%) 1.7910\n",
      "112m 45s (560 69%) 1.4364\n",
      "113m 36s (640 79%) 1.9542\n",
      "114m 21s (720 89%) 1.5120\n",
      "115m 2s (800 99%) 1.5466\n",
      "Epoch 14 115m 6s val loss: 1.8010 train loss: 1.4547\n",
      "\n",
      "115m 6s (0 0%) 1.6167\n",
      "115m 51s (80 9%) 1.5972\n",
      "116m 38s (160 19%) 1.7521\n",
      "117m 18s (240 29%) 1.0970\n",
      "118m 3s (320 39%) 0.9638\n",
      "118m 48s (400 49%) 2.9917\n",
      "119m 45s (480 59%) 2.2343\n",
      "120m 33s (560 69%) 1.4374\n",
      "121m 18s (640 79%) 0.7656\n",
      "122m 1s (720 89%) 1.6254\n",
      "122m 47s (800 99%) 1.2139\n",
      "Epoch 15 122m 50s val loss: 1.9039 train loss: 1.5514\n",
      "\n",
      "122m 51s (0 0%) 1.5657\n",
      "123m 34s (80 9%) 1.5887\n",
      "124m 19s (160 19%) 1.0063\n",
      "125m 9s (240 29%) 1.1810\n",
      "125m 59s (320 39%) 1.2320\n",
      "126m 44s (400 49%) 0.9403\n",
      "127m 25s (480 59%) 2.0304\n",
      "128m 11s (560 69%) 1.2077\n",
      "128m 56s (640 79%) 1.3347\n",
      "129m 35s (720 89%) 1.4705\n",
      "130m 30s (800 99%) 1.0367\n",
      "Epoch 16 130m 33s val loss: 1.8338 train loss: 1.4484\n",
      "\n",
      "130m 34s (0 0%) 1.3167\n",
      "131m 21s (80 9%) 1.3600\n",
      "132m 2s (160 19%) 1.3078\n",
      "132m 50s (240 29%) 1.1490\n",
      "133m 35s (320 39%) 1.1324\n",
      "134m 24s (400 49%) 1.4372\n",
      "135m 8s (480 59%) 1.7433\n",
      "135m 57s (560 69%) 1.1948\n",
      "136m 41s (640 79%) 1.0172\n",
      "137m 24s (720 89%) 1.5239\n",
      "138m 14s (800 99%) 1.5194\n",
      "Epoch 17 138m 18s val loss: 1.8271 train loss: 1.4272\n",
      "\n",
      "138m 18s (0 0%) 1.4247\n",
      "139m 1s (80 9%) 1.4782\n",
      "139m 45s (160 19%) 1.4041\n",
      "140m 34s (240 29%) 1.1067\n",
      "141m 14s (320 39%) 1.4066\n",
      "142m 3s (400 49%) 1.3098\n",
      "142m 54s (480 59%) 1.6248\n",
      "143m 38s (560 69%) 1.5223\n",
      "144m 24s (640 79%) 2.8644\n",
      "145m 10s (720 89%) 1.4278\n",
      "145m 59s (800 99%) 1.3388\n",
      "Epoch 18 146m 3s val loss: 1.7846 train loss: 1.3975\n",
      "\n",
      "146m 4s (0 0%) 1.2452\n",
      "146m 49s (80 9%) 1.6519\n",
      "147m 32s (160 19%) 1.4283\n",
      "148m 17s (240 29%) 1.5197\n",
      "149m 6s (320 39%) 1.2823\n",
      "149m 48s (400 49%) 1.2294\n",
      "150m 33s (480 59%) 0.7299\n",
      "151m 19s (560 69%) 1.2266\n",
      "152m 7s (640 79%) 1.5108\n",
      "152m 47s (720 89%) 1.1976\n",
      "153m 29s (800 99%) 1.7025\n",
      "Epoch 19 153m 34s val loss: 1.8068 train loss: 1.3931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rnn = RNN(n_chars, 128, n_chars).to(device)\n",
    "learning_rate = 0.05\n",
    "# optimizer = torch.optim.Adam(rnn.parameters())\n",
    "n_iters = 10000\n",
    "print_every = 80\n",
    "plot_every = 10\n",
    "# train_loss = []\n",
    "# val_loss = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "n_epochs = 20\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(int(start_epoch),int(start_epoch+n_epochs)):\n",
    "    shuffle(train_songs)\n",
    "    total_loss = 0\n",
    "    for i, song in enumerate(train_songs):\n",
    "        output, loss = train(song,optimizer=optimizer, device=device)\n",
    "        total_loss += loss\n",
    "        if i % print_every == 0:\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start), i, i / len(train_songs) * 100, loss))\n",
    "\n",
    "\n",
    "    train_loss.append(total_loss / len(train_songs))\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for song in test_songs:\n",
    "            _, loss = test(rnn, song, device=device)\n",
    "            total_loss += loss\n",
    "        val_loss.append(total_loss / len(test_songs))\n",
    "    torch.save(rnn.state_dict(),f'{name}_{epoch}.pt')\n",
    "    with open(f'{name}_train_loss_{epoch}.csv', 'w+') as out:\n",
    "        out.write('\\n'.join(map(str,train_loss)))\n",
    "\n",
    "    with open(f'{name}_val_loss_{epoch}.csv', 'w+') as out:\n",
    "        out.write('\\n'.join(map(str,val_loss)))\n",
    "    print('Epoch %d %s val loss: %.4f train loss: %.4f\\n' % (epoch,timeSince(start), val_loss[-1], train_loss[-1]))   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9528438598031443, 2.2151647763162448, 2.0113630294484635, 1.860778032240773, 1.7802630450627066, 1.7645563751748048, 1.6678513405999293, 1.6328713515158317, 1.5902879438904487, 1.6136337965947594, 1.5438609421993408, 1.5111104058449396, 1.48661406689443, 1.466830474650111, 1.4547097196262073, 1.551406508325355, 1.4483804386992722, 1.427182520707656, 1.3974729110345834, 1.3931004997673284]\n",
      "[2.4501790031112645, 2.3260973707847676, 1.981959513981076, 1.925464776147777, 1.9926372568526711, 1.8771435084852737, 1.8782816504358386, 1.834658883529107, 1.8345061652175592, 1.8515540325133606, 1.8130840754056576, 1.8711588833442425, 1.8174669449631375, 1.82164918171186, 1.8009552024747442, 1.903865505466558, 1.8338286399179802, 1.8270820508952257, 1.7845948928037216, 1.806842836515874]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "offset = 0\n",
    "epoch_nums = [i for i in range(len(train_loss)+1)]\n",
    "print(train_loss)\n",
    "print(val_loss)\n",
    "with open('train_loss_{offset}.csv', 'w+') as out:\n",
    "    out.write('\\n'.join(map(str,train_loss)))\n",
    "\n",
    "with open('val_loss_{offset}.csv', 'w+') as out:\n",
    "    out.write('\\n'.join(map(str,val_loss)))\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "X:75\n",
      "T:Le Rinuril Fronka Caerige ow in tou-li--ra cou-re- Joumier duro qui torin The\n",
      "D G, C, C,,,,,,B,,,C,,,C,,,,,,,,,,,,,,,C,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, |,,4,,,, D, D, | D,EC|\n",
      "Z:id:hn-jit-14\n",
      "M:2/4\n",
      "L:1/8\n",
      "K:A\n",
      "AF FE | A2 FD EC || CE GA | dB/B/ BB | AG FA | B2 B2 Ad AB | BB B2 B2 B2 |\n",
      "B6 BB GF GB | e6 |\n",
      "g4d e2e | ded dBA | G3 AAB | e3 dde | d3 : d dB AG | c2 BA GB | BA AF EF ED | EC B, FE B, G, |:\n",
      "E2 AB AB  | A2AF AGfe | eaga afge | bdga feed |\n",
      "dfdB A2F | G2B AAB | BGF AGF | ~B3 cAB | ded B2A | GeA dec | ^c2dB ge e2 | g2 fe dc |\n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "# Generates song using temperature of samples\n",
    "def sample_temp(temperature = 0.8):\n",
    "    with torch.no_grad():\n",
    "        input_tensor_chunk, _ = song_to_tensor_chunks(['<start>'], encoder, decoder)\n",
    "        input_tensor = input_tensor_chunk[0].to(device)\n",
    "        hidden = rnn.initHidden(device=device)\n",
    "        prev_char_raw, hidden = rnn(input_tensor,hidden) \n",
    "        prev_char_probs = torch.softmax(prev_char_raw, 2, prev_char_raw.dtype).view((n_chars))\n",
    "        output = '<start>'\n",
    "        while True:\n",
    "            output_dist = prev_char_raw.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "            selected_char = decoder[top_i.item()]\n",
    "            output += selected_char\n",
    "            input_tensor_chunk, _ = song_to_tensor_chunks([selected_char], encoder, decoder)\n",
    "            input_tensor = input_tensor_chunk[0].to(device)\n",
    "            # End song \n",
    "            if selected_char == '<end>':\n",
    "                break\n",
    "            # Get next letter \n",
    "            else:\n",
    "                prev_char_raw, hidden = rnn(input_tensor,hidden) \n",
    "                prev_char_probs = torch.softmax(prev_char_raw, 2, prev_char_raw.dtype).view((n_chars))\n",
    "        return output\n",
    "print(sample_temp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_char \n",
      "\n",
      "selected_char X\n",
      "selected_char :\n",
      "selected_char 1\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char M\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char n\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char a\n",
      "selected_char -\n",
      "selected_char -\n",
      "selected_char t\n",
      "selected_char o\n",
      "selected_char n\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char c\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char r\n",
      "selected_char e\n",
      "selected_char ,\n",
      "selected_char  \n",
      "selected_char T\n",
      "selected_char h\n",
      "selected_char e\n",
      "selected_char \n",
      "\n",
      "selected_char T\n",
      "selected_char :\n",
      "selected_char L\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char t\n",
      "selected_char a\n",
      "selected_char  \n",
      "selected_char b\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char e\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "selected_char -\n",
      "selected_char l\n",
      "selected_char i\n",
      "selected_char  \n",
      "selected_char d\n",
      "selected_char o\n",
      "selected_char u\n",
      "<start>\n",
      "X:1\n",
      "T:La chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou-li Ma-lin-ta de la bou-la--ton the chere, The\n",
      "T:Li ta bou-le dou-li dou-li dou<end>\n"
     ]
    }
   ],
   "source": [
    "def sample_max(max_length = 1000):\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        input_tensor_chunk, _ = song_to_tensor_chunks(['<start>'], encoder, decoder)\n",
    "        input_tensor = input_tensor_chunk[0].to(device)\n",
    "        hidden = rnn.initHidden(device=device)\n",
    "        prev_char_raw, hidden = rnn(input_tensor,hidden) \n",
    "        output = '<start>'\n",
    "        maxarg = torch.argmax(prev_char_raw)\n",
    "        while True:\n",
    "            selected_char = decoder[maxarg.item()]\n",
    "            print('selected_char', selected_char)\n",
    "            output += selected_char\n",
    "            input_tensor_chunk, _ = song_to_tensor_chunks([selected_char], encoder, decoder)\n",
    "            input_tensor = input_tensor_chunk[0].to(device)\n",
    "            # End of song\n",
    "            if selected_char == '<end>':\n",
    "                break\n",
    "            # Song is repeating and wont end\n",
    "            if counter == max_length:\n",
    "                output += '<end>'\n",
    "                break\n",
    "            else:\n",
    "                prev_char_raw, hidden = rnn(input_tensor,hidden) \n",
    "                maxarg = torch.argmax(prev_char_raw)\n",
    "            counter += 1\n",
    "        return output\n",
    "print(sample_max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dd89923cb042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normal run 20 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "# Normal run 20 epochs\n",
    "for i in range(6):\n",
    "    print(sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden size 64 run 16 epochs\n",
    "for i in range(6):\n",
    "    print(sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 20 epochs temp = 1 hidden size = 100\n",
    "for i in range(6):\n",
    "    print(sample_temp(.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
