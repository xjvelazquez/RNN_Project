# CSE154-RNN
## Generating Music with LSTM Networks
### Character level LSTM for music generation
In this assignment we will explore the power of Recurrent Neural Networks to deal with data that has temporal
structure. In this problem, we will generate music in abc format. You will train an LSTM model using characters
extracted from a music dataset provided to you and then run the network in generative mode to “compose” music.

#### 1. Getting familiar with the data
In this part, we are going to see how we can convert music from ABC
notation to a playable format(.midi in this case) online. Go to the website mandolintab.net/abcconverter.php.
Copy the text from sample-music.txt file (found under Data.zip,which contains music in ABC notation) and
hit Submit. Download the tune in midi format and play it on your computer

#### 2. Read in data
Read in the data from the train.txt (found under Data.zip) file. This file contains multiple
tunes in ABC format, with each tune delineated by <start> and <end> tags. Create a one-hot encoding of
the unique characters in the text data and create data structures to efficiently get the index of a character in
the encoding and vice-versa.
  
#### 3. Train a network
First, train an LSTM network to learn the structure of an ABC notation music file through
“Teacher Forcing”. Teacher forcing works by using the teaching signal from the training dataset at the
current time step, target(t), as input in the next time step x(t + 1) = target(t), rather than the output y(t)
generated by the network

#### 4. Generate music
In the generation stage, the idea is to “let the network run on its own”, predicting the next
character, and then use the network’s prediction to obtain the next input character. There are at least two
ways to obtain the next character: One is to take the maximum output. This is generally a bad idea, and
leads to unmusical output. Also, it is deterministic. The right way is to flip an n-sided coin, assuming n
outputs, based on the probability distribution at the softmax layer. You can make the network more or less
deterministic by adjusting the Temperature parameter T in the softmax, but start with 1. What’s interesting
about this is you should get a different piece of music each time from the same network and the same priming
(you can “prime” the network by giving it some initial characters from a song).

#### 5. Try different temperature values
Experiment with different temperatures during generation. Is there a
range that works better than 1?
