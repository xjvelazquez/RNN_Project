{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading in file and adding it to array to one hot encode. \n",
    "#file = open('samplemusic.txt')\n",
    "file = open('train.txt')\n",
    "tag = False\n",
    "part_tag = False\n",
    "array = []\n",
    "tag_string = ''\n",
    "while 1:\n",
    "    char = file.read(1)  # read by character\n",
    "    if not char: break\n",
    "        \n",
    "    # if char is beginning of tag\n",
    "    if char == '<':\n",
    "        part_tag = True\n",
    "        tag_string += char\n",
    "        \n",
    "    # if char is end of tag\n",
    "    elif char == '>':\n",
    "        # Checks if > is part of <start>/<end> tags or lone char\n",
    "        if tag_string == '<start' or tag_string == '<end':\n",
    "            tag = False\n",
    "            tag_string += char\n",
    "            array.append(tag_string)\n",
    "        # > is not part of tag, just lone char so we append it and reset the tag_string\n",
    "        else: \n",
    "            array.append(char)\n",
    "        tag_string = ''\n",
    "        \n",
    "    \n",
    "    # checks if char is still part of tag\n",
    "    elif part_tag == True:\n",
    "        # If next char after < is either s or e, we assume this is a tag.\n",
    "        if char == 's' or char == 'e':\n",
    "            tag = True\n",
    "            tag_string += char\n",
    "        # If not, < is just a lone char so append both separately\n",
    "        else:\n",
    "            array.append(tag_string)\n",
    "            array.append(char)\n",
    "            tag_string = ''\n",
    "        part_tag = False\n",
    "        \n",
    "    # If inside tag, keep adding chars to create full tag\n",
    "    elif tag == True:\n",
    "        tag_string += char\n",
    "            \n",
    "    # if char is not part of tag, just add char\n",
    "    elif tag == False:\n",
    "        array.append(char)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape or original data array: (185410, 1)\n",
      "Number of unique chars in array: 153\n",
      "[['<start>']]\n",
      "Shape of one-hot encoded data, X_data: (185410, 153)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding of data\n",
    "array = np.array(array).reshape(-1,1)\n",
    "print('Shape or original data array:', array.shape)\n",
    "print('Number of unique chars in array:', len(np.unique(array)))\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X_data = onehot_encoder.fit_transform(array) # Contains One hot encoding of all chars in text \n",
    "\n",
    "# Example of inversing one hot to get letter\n",
    "inverted = onehot_encoder.inverse_transform(X_data[0, :].reshape(1,-1))\n",
    "print(inverted)\n",
    "print('Shape of one-hot encoded data, X_data:', X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n"
     ]
    }
   ],
   "source": [
    "# Turning songs from data into chunks \n",
    "train_data = []\n",
    "song = []\n",
    "temp = []\n",
    "for idx in range(len(X_data)):\n",
    "    temp.append(X_data[idx]) # Add 100 chars into temp to create chunks \n",
    "    chara = onehot_encoder.inverse_transform(X_data[idx, :].reshape(1,-1))[0][0]\n",
    "    # Checks if char is at the end of a song \n",
    "    #print(chara)\n",
    "    if chara == '<end>':\n",
    "        song.append(temp)\n",
    "        train_data.append(song)\n",
    "        temp = []\n",
    "        song = []\n",
    "    \n",
    "    # If 100 chars in temp, add chunk to train_data\n",
    "    if idx%100 == 99:\n",
    "        song.append(temp)\n",
    "        temp = []\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "print(train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
    "\n",
    "        # Reshape input\n",
    "        x.view(x.size(0), self.sequence_length, self.input_size)\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        # Input: (batch, seq_len, input_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        return out.view(-1, num_classes), hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if torch.cuda.is_available():\n",
    "            hidden = torch.zeros(self.n_layers, 1, self.hidden_size).cuda()\n",
    "        else:\n",
    "            hidden = torch.zeros(self.n_layers, 1, self.hidden_size)\n",
    "\n",
    "        return Variable(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(777)  # reproducibility\n",
    "num_classes = train_data.shape[1]\n",
    "input_size = train_data.shape[1]  # one-hot size\n",
    "hidden_size = train_data.shape[1]  # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1   # one sentence\n",
    "sequence_length = 1  # One hundred sized chunks of text \n",
    "num_layers = 1  # one-layer rnn\n",
    "\n",
    "# Instantiate RNN model\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers).to(device)\n",
    "print(rnn)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.1)\n",
    "\n",
    "total_loss = []\n",
    "avg_minibatch_loss = []\n",
    "N = 50\n",
    "# Train the model\n",
    "for epoch in range(2):\n",
    "    N_chunk_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for song in range(len(train_data)):\n",
    "        optimizer.zero_grad()\n",
    "        for chunk in range(len(song)):\n",
    "            targets = np.roll(chunk, -1).to(device) # Targets is the chunk left shifted once\n",
    "            hidden = lstm.init_hidden() # Inits hidden state\n",
    "            loss = 0\n",
    "            for c in range(len(input)):\n",
    "                output, hidden = lstm(chunk[c], hidden)\n",
    "                loss += criterion(output, target[c])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            N_chunk_loss += loss\n",
    "    \n",
    "    print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data[0]))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
