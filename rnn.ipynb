{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading in file and adding it to array to one hot encode. \n",
    "#file = open('samplemusic.txt')\n",
    "file = open('train.txt')\n",
    "tag = False\n",
    "part_tag = False\n",
    "array = []\n",
    "tag_string = ''\n",
    "while 1:\n",
    "    char = file.read(1)  # read by character\n",
    "    if not char: break\n",
    "        \n",
    "    # if char is beginning of tag\n",
    "    if char == '<':\n",
    "        part_tag = True\n",
    "        tag_string += char\n",
    "        \n",
    "    # if char is end of tag\n",
    "    elif char == '>':\n",
    "        # Checks if > is part of <start>/<end> tags or lone char\n",
    "        if tag_string == '<start' or tag_string == '<end':\n",
    "            tag = False\n",
    "            tag_string += char\n",
    "            array.append(tag_string)\n",
    "        # > is not part of tag, just lone char so we append it and reset the tag_string\n",
    "        else: \n",
    "            array.append(char)\n",
    "        tag_string = ''\n",
    "        \n",
    "    \n",
    "    # checks if char is still part of tag\n",
    "    elif part_tag == True:\n",
    "        # If next char after < is either s or e, we assume this is a tag.\n",
    "        if char == 's' or char == 'e':\n",
    "            tag = True\n",
    "            tag_string += char\n",
    "        # If not, < is just a lone char so append both separately\n",
    "        else:\n",
    "            array.append(tag_string)\n",
    "            array.append(char)\n",
    "            tag_string = ''\n",
    "        part_tag = False\n",
    "        \n",
    "    # If inside tag, keep adding chars to create full tag\n",
    "    elif tag == True:\n",
    "        tag_string += char\n",
    "            \n",
    "    # if char is not part of tag, just add char\n",
    "    elif tag == False:\n",
    "        array.append(char)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape or original data array: (185410, 1)\n",
      "Number of unique chars in array: 153\n",
      "[['<start>']]\n",
      "Shape of one-hot encoded data, X_data: (185410, 153)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding of data\n",
    "array = np.array(array).reshape(-1,1)\n",
    "print('Shape or original data array:', array.shape)\n",
    "print('Number of unique chars in array:', len(np.unique(array)))\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X_data = onehot_encoder.fit_transform(array) # Contains One hot encoding of all chars in text \n",
    "\n",
    "# Example of inversing one hot to get letter\n",
    "inverted = onehot_encoder.inverse_transform(X_data[0, :].reshape(1,-1))\n",
    "print(inverted)\n",
    "print('Shape of one-hot encoded data, X_data:', X_data.shape)\n",
    "num_chars = X_data.shape[0]\n",
    "num_hot_encoding = X_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n"
     ]
    }
   ],
   "source": [
    "# Turning songs from data into chunks \n",
    "train_data = []\n",
    "song = []\n",
    "temp = []\n",
    "for idx in range(len(X_data)):\n",
    "    temp.append(X_data[idx]) # Add 100 chars into temp to create chunks \n",
    "    chara = onehot_encoder.inverse_transform(X_data[idx, :].reshape(1,-1))[0][0]\n",
    "    # Checks if char is at the end of a song \n",
    "    #print(chara)\n",
    "    if chara == '<end>':\n",
    "        song.append(np.array(temp))\n",
    "        train_data.append(np.array(song))\n",
    "        temp = []\n",
    "        song = []\n",
    "    \n",
    "    # If 100 chars in temp, add chunk to train_data\n",
    "    if idx%100 == 99:\n",
    "        song.append(np.array(temp))\n",
    "        temp = []\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "print(train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, *args):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
    "        hidden = args[0][0]\n",
    "        cell = args[0][1]\n",
    "        # Reshape input\n",
    "        x.view(1, self.sequence_length, self.input_size)\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        # Input: (batch, seq_len, input_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        out, (hidden, cell) = self.lstm(x, (hidden,cell))\n",
    "        return out.view(-1, num_classes), (hidden,cell)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if torch.cuda.is_available():\n",
    "            hidden = torch.zeros(self.num_layers, 1, self.hidden_size).cuda()\n",
    "            cell = torch.zeros(self.num_layers, 1, self.hidden_size).cuda()\n",
    "        else:\n",
    "            hidden = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "            cell = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "\n",
    "\n",
    "        return (Variable(hidden), Variable(cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 153)\n",
      "LSTM(\n",
      "  (lstm): LSTM(153, 153, batch_first=True)\n",
      ")\n",
      "out: torch.Size([100])\n",
      "targ: torch.Size([100])\n",
      "cont\n",
      "out: torch.Size([100])\n",
      "targ: torch.Size([100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ec7f9b7a2d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#    loss += criterion(output, torch.argmax(target_letter).view(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mN_chunk_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(777)  # reproducibility\n",
    "print(np.array(train_data[0][0]).shape)\n",
    "num_classes = num_hot_encoding\n",
    "input_size = num_hot_encoding  # one-hot size\n",
    "hidden_size = num_hot_encoding  # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1   # one sentence\n",
    "sequence_length = 100  # One hundred sized chunks of text \n",
    "num_layers = 1  # one-layer rnn\n",
    "\n",
    "# Instantiate RNN model\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers).to(device)\n",
    "print(lstm)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.1)\n",
    "\n",
    "total_loss = []\n",
    "avg_chunk_loss = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(2):\n",
    "    N_chunk_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    song_count = 0\n",
    "    for song in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        hidden_cont = None\n",
    "        for chunk_count, chunk in enumerate(song):\n",
    "            targets = np.roll(chunk, -1) # Targets is the chunk left shifted once\n",
    "            # If chunk is first one in song, init hidden state, else keep hidden state for next chunk\n",
    "            if chunk_count == 0:\n",
    "                (hidden, cell) = lstm.init_hidden() # Inits hidden state\n",
    "            else:\n",
    "                print('cont')\n",
    "                (hidden, cell) = hidden_cont\n",
    "            loss = 0\n",
    "            \n",
    "            letter = Variable(torch.Tensor(chunk)).view(1,-1,153).to(device)\n",
    "            target_letter = Variable(torch.LongTensor(targets)).view(1,-1,153).to(device)\n",
    "            output, (hidden, cell) = lstm(letter, (hidden, cell))\n",
    "            hidden_cont = (hidden, cell)\n",
    "            print('out:', torch.argmax(output, dim=1).size())\n",
    "            print('targ:', torch.argmax(target_letter, dim=2).squeeze().size())\n",
    "            loss += criterion(output, torch.argmax(target_letter, dim=2).squeeze())\n",
    "            #for c in range(len(chunk)):\n",
    "            #    letter = Variable(torch.Tensor(chunk[c])).view(1,1,153).to(device)\n",
    "            #    target_letter = Variable(torch.LongTensor(targets[c])).view(1,1,153).to(device)\n",
    "            #    output, (hidden, cell) = lstm(letter, (hidden,cell))\n",
    "            #    hidden_cont = (hidden, cell)\n",
    "            #    #print('output:', torch.argmax(output))\n",
    "            #    #print('target:', torch.argmax(target_letter).view(1))\n",
    "            #    loss += criterion(output, torch.argmax(target_letter).view(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            N_chunk_loss += loss\n",
    "            \n",
    "            #Print the loss averaged over the last N mini-batches\n",
    "            N_chunk_loss /= 1\n",
    "            #print('Epoch %d, average minibatch loss: %.3f' % (epoch + 1, N_chunk_loss))\n",
    "            # Add the averaged loss over N minibatches and reset the counter\n",
    "            avg_chunk_loss.append(N_chunk_loss)\n",
    "            N_chunk_loss = 0.0\n",
    "        print(\"Finished\", song_count + 1, \"/333 songs of training\")\n",
    "        song_count += 1\n",
    "    print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data[0]))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
