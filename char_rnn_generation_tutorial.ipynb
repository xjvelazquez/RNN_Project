{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on NLP From Scratch: Generating Names with a Character-Level RNN\n",
    "*************************************************************\n",
    "by: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import random\n",
    "from random import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,num_layers=1, bias=True, batch_first=False,\n",
    "                dropout=0, bidirectional=False):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, bias=bias, batch_first=batch_first,\n",
    "                           dropout=dropout, bidirectional=bidirectional)\n",
    "#         self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "#         self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "\n",
    "        self.o2o = nn.Linear(self.num_directions * hidden_size, output_size)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, my_input, hidden):\n",
    "#         input_combined = torch.cat((category, input, hidden), 1)\n",
    "#         hidden = self.i2h(input_combined)\n",
    "#         output = self.i2o(input_combined)\n",
    "#         output_combined = torch.cat((hidden, output), 1)\n",
    "#         output = self.o2o(output_combined)\n",
    "#         output = self.dropout(output)\n",
    "        output, hidden = self.lstm(my_input, hidden)\n",
    "        output = self.o2o(output)\n",
    "#         output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch=1, device=torch.device('cpu')):\n",
    "        return (torch.zeros(self.num_layers,1,self.hidden_size, device=device), torch.zeros(self.num_layers * self.num_directions,batch,self.hidden_size,device=device))\n",
    "#         return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def string_to_chars(original):\n",
    "    raw_lines = original.splitlines()\n",
    "\n",
    "    def proc_line(l): return [l] if l == '<start>' or l == '<end>' else list(l)\n",
    "    chars = reduce(lambda x, y : x + ['\\n'] + y, list(map(proc_line, raw_lines)))\n",
    "    assert original == ''.join(chars)\n",
    "    return chars\n",
    "\n",
    "def make_encoder(raw):\n",
    "    chars = string_to_chars(raw)\n",
    "    decoder = [c for c in Counter(chars)]\n",
    "    decoder = sorted(decoder)\n",
    "    return {c:i for i, c in enumerate(decoder)}, decoder\n",
    "\n",
    "def split_songs(raw):\n",
    "    return re.findall('(<start>.*?<end>)',raw,flags=re.DOTALL)\n",
    "\n",
    "# train_songs = list(map(string_to_chars, split_songs(raw_train)))\n",
    "\n",
    "# reconstructed = '\\n'.join(map(''.join, train_songs))\n",
    "# encoder, decoder = make_encoder(raw_train)\n",
    "# n_chars = len(decoder)\n",
    "\n",
    "def song_to_tensor_chunks(song,encoder, decoder):\n",
    "    training_chunks = []\n",
    "    target_chunks = []\n",
    "    for i in range(0,len(song),100):\n",
    "        start = i\n",
    "        if start+100 > len(song) - 1:\n",
    "            end = len(song)\n",
    "            target_range = list(np.arange(start + 1, end,dtype=np.int)) + [int(end - 1)]\n",
    "        else:\n",
    "            end = start + 100\n",
    "            target_range = np.arange(start+1, end+1, dtype=np.int)\n",
    "        chunk = torch.zeros(end-start, 1, n_chars)\n",
    "        for i, c in enumerate(song[start:end]):\n",
    "            chunk[i,0,encoder[c]] = 1\n",
    "        target_chunk = []\n",
    "        for i in target_range:\n",
    "            target_chunk.append(encoder[song[i]])\n",
    "        target_chunks.append(torch.tensor(target_chunk))\n",
    "        training_chunks.append(chunk)\n",
    "    return training_chunks, target_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = open('train.txt').read()\n",
    "train_songs = list(map(string_to_chars, split_songs(raw_train)))\n",
    "\n",
    "reconstructed = '\\n'.join(map(''.join, train_songs))\n",
    "encoder, decoder = make_encoder(raw_train)\n",
    "n_chars = len(decoder)\n",
    "val_songs = list(map(string_to_chars, split_songs(open('val.txt').read())))\n",
    "test_songs = list(map(string_to_chars, split_songs(open('test.txt').read())))\n",
    "assert reconstructed == raw_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience during training we'll make a ``randomTrainingExample``\n",
    "function that fetches a random (category, line) pair and turns them into\n",
    "the required (category, input, target) tensors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network\n",
    "--------------------\n",
    "\n",
    "In contrast to classification, where only the last output is used, we\n",
    "are making a prediction at every step, so we are calculating loss at\n",
    "every step.\n",
    "\n",
    "The magic of autograd allows you to simply sum these losses at each step\n",
    "and call backward at the end.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(song,optimizer=None, device=torch.device('cpu')):\n",
    "    train_chunks, target_chunks = song_to_tensor_chunks(song, encoder,decoder)\n",
    "    hidden = rnn.initHidden(device=device)\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for input_line_tensor, target_line_tensor in zip(train_chunks,target_chunks):\n",
    "        target_line_tensor.unsqueeze_(-1)\n",
    "        for i in range(input_line_tensor.size(0)):\n",
    "            output, hidden = rnn(input_line_tensor[i].view((1,1,n_chars)).to(device), hidden)\n",
    "    #         print(output)\n",
    "            l = criterion(output.view((1,n_chars)), target_line_tensor[i].to(device))\n",
    "            loss += l / input_line_tensor.size(0)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item() / len(train_chunks)\n",
    "def test(rnn, song, device=torch.device('cpu')):\n",
    "    train_chunks, target_chunks = song_to_tensor_chunks(song, encoder,decoder)\n",
    "    hidden = rnn.initHidden(device=device)\n",
    "    loss = 0\n",
    "    for input_line_tensor, target_line_tensor in zip(train_chunks,target_chunks):\n",
    "        target_line_tensor.unsqueeze_(-1)\n",
    "        output, hidden = rnn(input_line_tensor.to(device), hidden)\n",
    "        seq_len,_ =target_line_tensor.size()\n",
    "        l = criterion(output.view((seq_len,n_chars)), target_line_tensor.view((seq_len)).to(device))\n",
    "        loss += l\n",
    "    return output, loss.item() / len(train_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_chars, 128, n_chars).to(device)\n",
    "rnn.load_state_dict(torch.load('rnn_9.pt'))\n",
    "rnn = rnn.to(device)\n",
    "train_loss = list(map(float,(open('train_loss_9.csv').read().splitlines())))\n",
    "val_loss = list(map(float,(open('val_loss_9.csv').read().splitlines())))\n",
    "print(len(train_loss))\n",
    "start = len(train_loss)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (0 0%) 1.8987\n",
      "0m 30s (80 9%) 1.4939\n",
      "0m 59s (160 19%) 1.7172\n",
      "1m 30s (240 29%) 1.5937\n",
      "1m 59s (320 39%) 1.3314\n",
      "2m 32s (400 49%) 1.4011\n",
      "3m 3s (480 59%) 0.8306\n",
      "3m 32s (560 69%) 1.3003\n",
      "4m 8s (640 79%) 1.3434\n",
      "6m 21s (160 19%) 1.1020\n",
      "6m 53s (240 29%) 1.1515\n",
      "7m 23s (320 39%) 1.6751\n",
      "8m 0s (400 49%) 1.4564\n",
      "8m 30s (480 59%) 1.5474\n",
      "9m 1s (560 69%) 1.8963\n",
      "9m 35s (640 79%) 1.3625\n",
      "10m 5s (720 89%) 1.3778\n",
      "10m 37s (800 99%) 1.2993\n",
      "Epoch 1574735852 10m 40s val loss: 1.6241 train loss: 1.3659\n",
      "\n",
      "10m 40s (0 0%) 1.3699\n",
      "11m 14s (80 9%) 1.0825\n",
      "11m 46s (160 19%) 1.2589\n",
      "12m 15s (240 29%) 1.4794\n",
      "12m 49s (320 39%) 1.8845\n",
      "13m 20s (400 49%) 1.2653\n",
      "13m 57s (480 59%) 0.7129\n",
      "14m 31s (560 69%) 1.6904\n",
      "14m 59s (640 79%) 1.1877\n",
      "15m 28s (720 89%) 1.3356\n",
      "15m 55s (800 99%) 1.1414\n",
      "Epoch 1574735853 15m 57s val loss: 1.6071 train loss: 1.3338\n",
      "\n",
      "15m 57s (0 0%) 1.8355\n",
      "16m 30s (80 9%) 1.8466\n",
      "17m 0s (160 19%) 1.7612\n",
      "17m 36s (240 29%) 1.9991\n",
      "18m 6s (320 39%) 1.1711\n",
      "18m 36s (400 49%) 0.6791\n",
      "19m 6s (480 59%) 2.0664\n",
      "19m 37s (560 69%) 1.5466\n",
      "20m 7s (640 79%) 1.3824\n",
      "20m 42s (720 89%) 1.3508\n",
      "21m 14s (800 99%) 1.5272\n",
      "Epoch 1574735854 21m 17s val loss: 1.6335 train loss: 1.3100\n",
      "\n",
      "21m 17s (0 0%) 1.0391\n",
      "21m 50s (80 9%) 1.4915\n",
      "22m 20s (160 19%) 0.6798\n",
      "22m 54s (240 29%) 1.3871\n",
      "23m 24s (320 39%) 0.9676\n",
      "23m 53s (400 49%) 1.6101\n",
      "24m 24s (480 59%) 1.4930\n",
      "24m 56s (560 69%) 0.8462\n",
      "25m 28s (640 79%) 1.5243\n",
      "25m 59s (720 89%) 1.3233\n",
      "26m 35s (800 99%) 1.0736\n",
      "Epoch 1574735855 26m 38s val loss: 1.6299 train loss: 1.2885\n",
      "\n",
      "26m 38s (0 0%) 1.2251\n",
      "27m 11s (80 9%) 1.2771\n",
      "27m 46s (160 19%) 0.8755\n",
      "28m 14s (240 29%) 1.3373\n",
      "28m 42s (320 39%) 1.0555\n",
      "29m 17s (400 49%) 1.8243\n",
      "29m 46s (480 59%) 1.3693\n",
      "30m 19s (560 69%) 1.1573\n",
      "30m 52s (640 79%) 1.1030\n",
      "31m 23s (720 89%) 1.1347\n",
      "31m 54s (800 99%) 1.0099\n",
      "Epoch 1574735856 31m 57s val loss: 1.5863 train loss: 1.2684\n",
      "\n",
      "31m 57s (0 0%) 1.2759\n",
      "32m 29s (80 9%) 1.3192\n",
      "32m 59s (160 19%) 1.0212\n",
      "33m 35s (240 29%) 1.2028\n",
      "34m 7s (320 39%) 1.1521\n",
      "34m 37s (400 49%) 1.2337\n",
      "35m 10s (480 59%) 1.1063\n",
      "35m 39s (560 69%) 1.7221\n",
      "36m 7s (640 79%) 1.0584\n",
      "36m 45s (720 89%) 1.1444\n",
      "37m 14s (800 99%) 1.0929\n",
      "Epoch 1574735857 37m 17s val loss: 1.5780 train loss: 1.2455\n",
      "\n",
      "37m 17s (0 0%) 1.1438\n",
      "37m 47s (80 9%) 1.2181\n",
      "38m 18s (160 19%) 1.2598\n",
      "38m 48s (240 29%) 1.0566\n",
      "39m 22s (320 39%) 1.0902\n",
      "39m 49s (400 49%) 1.0774\n",
      "40m 18s (480 59%) 0.9410\n",
      "40m 47s (560 69%) 1.4943\n",
      "41m 21s (640 79%) 0.8250\n",
      "41m 54s (720 89%) 1.3424\n",
      "42m 32s (800 99%) 1.0774\n",
      "Epoch 1574735858 42m 35s val loss: 1.5835 train loss: 1.2280\n",
      "\n",
      "42m 35s (0 0%) 1.4997\n",
      "43m 6s (80 9%) 0.8857\n",
      "43m 35s (160 19%) 1.1622\n",
      "44m 11s (240 29%) 0.9892\n",
      "44m 42s (320 39%) 1.1947\n",
      "45m 14s (400 49%) 1.2989\n",
      "45m 47s (480 59%) 1.1390\n",
      "46m 15s (560 69%) 1.1106\n",
      "46m 48s (640 79%) 1.1514\n",
      "47m 17s (720 89%) 1.3765\n",
      "47m 52s (800 99%) 0.8958\n",
      "Epoch 1574735859 47m 55s val loss: 1.5673 train loss: 1.2125\n",
      "\n",
      "47m 56s (0 0%) 1.0456\n",
      "48m 30s (80 9%) 1.3912\n",
      "49m 2s (160 19%) 0.8664\n",
      "49m 32s (240 29%) 1.4234\n",
      "50m 5s (320 39%) 0.9139\n",
      "50m 38s (400 49%) 1.2027\n",
      "51m 10s (480 59%) 1.2333\n",
      "51m 41s (560 69%) 1.0855\n",
      "52m 14s (640 79%) 0.8067\n",
      "52m 43s (720 89%) 1.3422\n",
      "53m 15s (800 99%) 1.3091\n",
      "Epoch 1574735860 53m 17s val loss: 1.5874 train loss: 1.1955\n",
      "\n",
      "53m 18s (0 0%) 1.0808\n",
      "53m 51s (80 9%) 1.4055\n",
      "54m 24s (160 19%) 1.0017\n",
      "54m 58s (240 29%) 1.1724\n",
      "55m 34s (320 39%) 0.8866\n",
      "56m 4s (400 49%) 0.9543\n",
      "56m 33s (480 59%) 1.4236\n",
      "57m 6s (560 69%) 1.3092\n",
      "57m 36s (640 79%) 1.0521\n",
      "58m 9s (720 89%) 1.1950\n",
      "58m 38s (800 99%) 1.3813\n",
      "Epoch 1574735861 58m 40s val loss: 1.5749 train loss: 1.1815\n",
      "\n",
      "58m 41s (0 0%) 1.3466\n",
      "59m 10s (80 9%) 0.8327\n",
      "59m 41s (160 19%) 1.0010\n",
      "60m 14s (240 29%) 1.0930\n",
      "60m 45s (320 39%) 0.9749\n",
      "61m 17s (400 49%) 1.2535\n",
      "61m 51s (480 59%) 1.0068\n",
      "62m 22s (560 69%) 1.2886\n",
      "62m 55s (640 79%) 1.0819\n",
      "63m 25s (720 89%) 0.7962\n",
      "63m 57s (800 99%) 0.9867\n",
      "Epoch 1574735862 64m 0s val loss: 1.5584 train loss: 1.1651\n",
      "\n",
      "64m 1s (0 0%) 1.1270\n",
      "64m 34s (80 9%) 1.3046\n",
      "65m 5s (160 19%) 0.9792\n"
     ]
    }
   ],
   "source": [
    "# rnn = RNN(n_chars, 128, n_chars).to(device)\n",
    "learning_rate = 0.05\n",
    "# optimizer = torch.optim.Adam(rnn.parameters())\n",
    "n_iters = 10000\n",
    "print_every = 80\n",
    "plot_every = 10\n",
    "# train_loss = []\n",
    "# val_loss = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "n_epochs = 20\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(int(start),int(start+n_epochs)):\n",
    "    shuffle(train_songs)\n",
    "    total_loss = 0\n",
    "    for i, song in enumerate(train_songs):\n",
    "        output, loss = train(song,optimizer=optimizer, device=device)\n",
    "        total_loss += loss\n",
    "        if i % print_every == 0:\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start), i, i / len(train_songs) * 100, loss))\n",
    "\n",
    "\n",
    "    train_loss.append(total_loss / len(train_songs))\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for song in test_songs:\n",
    "            _, loss = test(rnn, song, device=device)\n",
    "            total_loss += loss\n",
    "        val_loss.append(total_loss / len(test_songs))\n",
    "    torch.save(rnn.state_dict(),f'rnn_{epoch}.pt')\n",
    "    with open(f'train_loss_{epoch}.csv', 'w+') as out:\n",
    "        out.write('\\n'.join(map(str,train_loss)))\n",
    "\n",
    "    with open(f'val_loss_{epoch}.csv', 'w+') as out:\n",
    "        out.write('\\n'.join(map(str,val_loss)))\n",
    "    print('Epoch %d %s val loss: %.4f train loss: %.4f\\n' % (epoch,timeSince(start), val_loss[-1], train_loss[-1]))   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "offset = 0\n",
    "print(train_loss)\n",
    "print(val_loss)\n",
    "with open('train_loss_{offset}.csv', 'w+') as out:\n",
    "    out.write('\\n'.join(map(str,train_loss)))\n",
    "\n",
    "with open('val_loss_{offset}.csv', 'w+') as out:\n",
    "    out.write('\\n'.join(map(str,val_loss)))\n",
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start>\\nX:29\\nT:Maudro Samem\\nM:4/8\\nL:1/4\\nK:Gm\\nGc | cB AB | AF Ac |\\nA2 Bc | {d}d3 fe | cB cA | BA BA | F/G/A/B/ cA | \\ne2 B | A2 cB :| B2 Bd | cB BA | BB BA | G2 GB |\\nAB cB | Ac EA| BA Ac | B2 ef/e/ | dB AF | D2 F2 ||\\n<end>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def sample():\n",
    "    with torch.no_grad():\n",
    "        input_tensor_chunk, _ = song_to_tensor_chunks(['<start>'], encoder, decoder)\n",
    "        input_tensor = input_tensor_chunk[0].to(device)\n",
    "        hidden = rnn.initHidden(device=device)\n",
    "        prev_char_raw, hidden =rnn(input_tensor,hidden) \n",
    "        prev_char_probs = torch.softmax(prev_char_raw, 2, prev_char_raw.dtype).view((n_chars))\n",
    "        output = '<start>'\n",
    "        while True:\n",
    "            selection = np.random.random()\n",
    "            running_prob = 0\n",
    "            for i, prob in enumerate(prev_char_probs):\n",
    "                running_prob += prob\n",
    "                if running_prob > selection:\n",
    "                    selected_char = decoder[i]\n",
    "                    output += selected_char\n",
    "                    input_tensor_chunk, _ = song_to_tensor_chunks([selected_char], encoder, decoder)\n",
    "                    input_tensor = input_tensor_chunk[0].to(device)\n",
    "                    break\n",
    "            if selected_char == '<end>':\n",
    "                break\n",
    "            else:\n",
    "                prev_char_raw, hidden =rnn(input_tensor,hidden) \n",
    "                prev_char_probs = torch.softmax(prev_char_raw, 2, prev_char_raw.dtype).view((n_chars))\n",
    "        return output\n",
    "\n",
    "print(sample())\n",
    "# # Sample from a category and starting letter\n",
    "# def sample(category, start_letter='A'):\n",
    "#     with torch.no_grad():  # no need to track history in sampling\n",
    "#         category_tensor = categoryTensor(category)\n",
    "#         input = inputTensor(start_letter)\n",
    "#         hidden = rnn.initHidden()\n",
    "\n",
    "#         output_name = start_letter\n",
    "\n",
    "#         for i in range(max_length):\n",
    "#             output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "#             topv, topi = output.topk(1)\n",
    "#             topi = topi[0][0]\n",
    "#             if topi == n_letters - 1:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 letter = all_letters[topi]\n",
    "#                 output_name += letter\n",
    "#             input = inputTensor(letter)\n",
    "\n",
    "#         return output_name\n",
    "\n",
    "# # Get multiple samples from one category and multiple starting letters\n",
    "# def samples(category, start_letters='ABC'):\n",
    "#     for start_letter in start_letters:\n",
    "#         print(sample(category, start_letter))\n",
    "\n",
    "# samples('Russian', 'RUS')\n",
    "\n",
    "# samples('German', 'GER')\n",
    "\n",
    "# samples('Spanish', 'SPA')\n",
    "\n",
    "# samples('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "X:29\n",
      "T:Maudro Samem\n",
      "M:4/8\n",
      "L:1/4\n",
      "K:Gm\n",
      "Gc | cB AB | AF Ac |\n",
      "A2 Bc | {d}d3 fe | cB cA | BA BA | F/G/A/B/ cA | \n",
      "e2 B | A2 cB :| B2 Bd | cB BA | BB BA | G2 GB |\n",
      "AB cB | Ac EA| BA Ac | B2 ef/e/ | dB AF | D2 F2 ||\n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "print('<start>\\nX:29\\nT:Maudro Samem\\nM:4/8\\nL:1/4\\nK:Gm\\nGc | cB AB | AF Ac |\\nA2 Bc | {d}d3 fe | cB cA | BA BA | F/G/A/B/ cA | \\ne2 B | A2 cB :| B2 Bd | cB BA | BB BA | G2 GB |\\nAB cB | Ac EA| BA Ac | B2 ef/e/ | dB AF | D2 F2 ||\\n<end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
